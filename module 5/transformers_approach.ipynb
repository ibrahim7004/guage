{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(r'C:\\Users\\hp\\Desktop\\preply\\lars\\project\\module 5\\preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Highlights</th>\n",
       "      <th>Investment Rationale</th>\n",
       "      <th>Industry Outlook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EQUITY Factsheet_ A.P. Moller - Maersk A_S</td>\n",
       "      <td>['maersk', 'ebitda', 'billion', 'consensu', 'e...</td>\n",
       "      <td>['call', 'sell', 'believ', 'maersk', 'financi'...</td>\n",
       "      <td>['maintain', 'sector', 'recommend', 'emea', 'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EQUITY Factsheet_ Abbott Laboratories</td>\n",
       "      <td>['expect', 'total', 'sale', 'contract', 'billi...</td>\n",
       "      <td>['think', 'share', 'abt', 'outperform', 'marke...</td>\n",
       "      <td>['fundament', 'outlook', 'health', 'care', 'eq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EQUITY Factsheet_ AbbVie Inc.</td>\n",
       "      <td>['expect', 'revenu', 'growth', 'billion', 'dec...</td>\n",
       "      <td>['opinion', 'share', 'abbvi', 'hold', 'follow'...</td>\n",
       "      <td>['neutral', 'outlook', 'biotech', 'expect', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EQUITY Factsheet_ Adobe Inc. (1)</td>\n",
       "      <td>['project', 'sale', 'grow', 'fy', 'fy', 'compa...</td>\n",
       "      <td>['buy', 'recommend', 'reflect', 'view', 'poten...</td>\n",
       "      <td>['cfra', 'posit', 'fundament', 'outlook', 'app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EQUITY Factsheet_ Advanced Energy Industries Inc.</td>\n",
       "      <td>['tight', 'suppli', 'condit', 'hurt', 'aei', '...</td>\n",
       "      <td>['follow', 'extend', 'period', 'aei', 'abil', ...</td>\n",
       "      <td>['neutral', 'fundament', 'outlook', 'electron'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0         EQUITY Factsheet_ A.P. Moller - Maersk A_S   \n",
       "1              EQUITY Factsheet_ Abbott Laboratories   \n",
       "2                      EQUITY Factsheet_ AbbVie Inc.   \n",
       "3                   EQUITY Factsheet_ Adobe Inc. (1)   \n",
       "4  EQUITY Factsheet_ Advanced Energy Industries Inc.   \n",
       "\n",
       "                                          Highlights  \\\n",
       "0  ['maersk', 'ebitda', 'billion', 'consensu', 'e...   \n",
       "1  ['expect', 'total', 'sale', 'contract', 'billi...   \n",
       "2  ['expect', 'revenu', 'growth', 'billion', 'dec...   \n",
       "3  ['project', 'sale', 'grow', 'fy', 'fy', 'compa...   \n",
       "4  ['tight', 'suppli', 'condit', 'hurt', 'aei', '...   \n",
       "\n",
       "                                Investment Rationale  \\\n",
       "0  ['call', 'sell', 'believ', 'maersk', 'financi'...   \n",
       "1  ['think', 'share', 'abt', 'outperform', 'marke...   \n",
       "2  ['opinion', 'share', 'abbvi', 'hold', 'follow'...   \n",
       "3  ['buy', 'recommend', 'reflect', 'view', 'poten...   \n",
       "4  ['follow', 'extend', 'period', 'aei', 'abil', ...   \n",
       "\n",
       "                                    Industry Outlook  \n",
       "0  ['maintain', 'sector', 'recommend', 'emea', 'i...  \n",
       "1  ['fundament', 'outlook', 'health', 'care', 'eq...  \n",
       "2  ['neutral', 'outlook', 'biotech', 'expect', 'l...  \n",
       "3  ['cfra', 'posit', 'fundament', 'outlook', 'app...  \n",
       "4  ['neutral', 'fundament', 'outlook', 'electron'...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['maintain', 'sector', 'recommend', 'emea', 'industri', 'sector', 'neutral', 'believ', 'key', 'issu', 'face', 'sector', 'surg', 'energi', 'price', 'aris', 'concern', 'potenti', 'suppli', 'disrupt', 'middl', 'howev', 'suppli', 'chain', 'disrupt', 'could', 'attribut', 'slower', 'demand', 'good', 'weak', 'economi', 'growth', 'past', 'month', 'shanghai', 'container', 'freight', 'index', 'scfi', 'declin', 'per', 'signal', 'weak', 'demand', 'global', 'movement', 'year', 'date', 'octob', 'emea', 'industri', 'index', 'p', 'versu', 'europ', 'index', 'increas', 'howev', 'emea', 'industri', 'sector', 'perform', 'europ', 'eurozon', 'annual', 'inflat', 'rate', 'drop', 'septemb', 'august', 'expect', 'lower', 'inflat', 'impact', 'posit', 'industri', 'sector', 'earn', 'lower', 'cost', 'widen', 'oper', 'industri', 'player', 'like', 'focu', 'revenu', 'growth', 'via', 'busi', 'volum', 'increas', 'instead', 'averag', 'sell', 'price', 'outlook', 'turn', 'posit', 'inflat', 'moder', 'although', 'partial', 'caus', 'high', 'base', 'case', 'comparison', 'howev', 'growth', 'momentum', 'like', 'slow', 'factor', 'china', 'reopen', 'far', 'gener', 'littl', 'demand', 'view', 'industri', 'player', 'shift', 'focu', 'grow', 'volum', 'instead', 'pass', 'increas', 'cost', 'inflat', 'cool', 'eurozon', 'manufactur', 'pmi', 'septemb', 'stand', 'littl', 'chang', 'compar', 'august', 'level', 'accord', 'find', 'contract', 'order', 'book', 'output', 'declin', 'trend', 'still', 'posit', 'side', 'price', 'input', 'materi', 'declin', 'manufactur', 'pass', 'cost', 'save', 'due', 'aircraft', 'engin', 'recal', 'issu', 'gear', 'turbofan', 'engin', 'neutral', 'aerospac', 'defens', 'posit', 'also', 'lower', 'opinion', 'neutral', 'although', 'airlin', 'player', 'like', 'benefit', 'global', 'aviat', 'sector', 'recoveri', 'due', 'normal', 'margin', 'could', 'affect', 'spike', 'jet', 'fuel', 'price', 'line', 'higher', 'crude', 'oil', 'price', 'posit', 'industri', 'machineri', 'industri', 'conglomer', 'industri', 'machineri', 'player', 'beneficiari', 'high', 'demand', 'due', 'energi', 'effici', 'industri', 'conglomer', 'strong', 'demand', 'electrif', 'sustain', 'servic', 'continu', 'support', 'revenu', 'focu', 'trade', 'compani', 'distributor', 'reduc', 'inventori', 'near', 'term', 'may', 'affect', 'margin', 'although', 'could', 'lead', 'stronger', 'cash', 'heavi', 'electr', 'equip', 'smoother', 'suppli', 'chain', 'lead', 'improv', 'revenu', 'howev', 'intens', 'competit', 'keep', 'margin', 'pside', 'less', 'posit', 'build', 'product', 'construct', 'machineri', 'heavi', 'truck', 'expect', 'build', 'product', 'revenu', 'affect', 'poor', 'demand', 'properti', 'slow', 'economi', 'construct', 'machineri', 'heavi', 'truck', 'sector', 'slower', 'economi', 'europ', 'affect', 'construct', 'activ', 'truck', 'demand', 'roll', 'alan', 'lim', 'seong', 'chun', 'cf']\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['Industry Outlook'][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2847"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tokens):\n",
    "    outputs = model(**tokens)   # pass tokens to get output\n",
    "    probabilities = torch.nn.functional.softmax(outputs[0], dim=-1) # Convert retrieved outputs to probabilities\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [48759, 119, 37205, 3934, 128, 18658, 3934, 128, 43140, 1397, 3934, 128, 991, 13184, 3934, 128, 21267, 1069, 3934, 128, 18658, 3934, 128, 12516, 3934, 128, 8494, 18421, 3934, 128, 5282, 3934, 128, 3006, 257, 3934, 128, 9021, 3934, 128, 18658, 3934, 128, 29, 7150, 3934, 128, 5777, 15696, 3934, 128, 17212, 3934, 128, 17661, 3934, 128, 3865, 38987, 3934, 128, 8024, 1342, 118, 3934, 128, 16714, 3572, 3934, 128, 7779, 14709, 3934, 128, 119, 6502, 462, 3934, 128, 9178, 3623, 3934, 128, 16714, 3572, 3934, 128, 26149, 3934, 128, 7779, 14709, 3934, 128, 17304, 3934, 128, 2611, 24008, 3934, 128, 9996, 8285, 3934, 128, 15509, 3934, 128, 8396, 3934, 128, 25785, 3934, 128, 28310, 118, 3934, 128, 14596, 3934, 128, 33456, 3934, 128, 2151, 3934, 128, 1193, 260, 43673, 3934, 128, 46367, 3934, 128, 18178, 5971, 3934, 128, 18480, 3934, 128, 3866, 9169, 3934, 128, 32639, 179, 3934, 128, 1741, 3934, 128, 13033, 337, 3934, 128, 25785, 3934, 128, 15509, 3934, 128, 9424, 3934, 128, 30191, 1757, 3934, 128, 180, 3934, 128, 10672, 3934, 128, 32643, 2413, 3934, 128, 991, 13184, 3934, 128, 21267, 1069, 3934, 128, 18480, 3934, 128, 642, 3934, 128, 3697, 257, 3934, 128, 23286, 642, 3934, 128, 18480, 3934, 128, 33008, 281, 3934, 128, 9178, 3623, 3934, 128, 991, 13184, 3934, 128, 21267, 1069, 3934, 128, 18658, 3934, 128, 1741, 3899, 3934, 128, 23286, 642, 3934, 128, 23286, 15892, 3934, 128, 2279, 5564, 3934, 128, 179, 35429, 3934, 128, 7954, 3934, 128, 32597, 3934, 128, 1090, 3320, 20506, 3934, 128, 12361, 4193, 3934, 128, 3463, 13771, 3934, 128, 29668, 3934, 128, 179, 35429, 3934, 128, 32158, 3934, 128, 11474, 405, 3934, 128, 21267, 1069, 3934, 128, 18658, 3934, 128, 4352, 282, 3934, 128, 29668, 3934, 128, 10111, 3934, 128, 605, 12145, 3934, 128, 8428, 3934, 128, 21267, 1069, 3934, 128, 23233, 3934, 128, 3341, 3934, 128, 506, 1975, 257, 3934, 128, 241, 2987, 257, 3934, 128, 14596, 3934, 128, 11409, 3934, 128, 18924, 118, 3934, 128, 13728, 783, 3934, 128, 33008, 281, 3934, 128, 38908, 3934, 128, 9903, 1073, 3934, 128, 5727, 3934, 128, 17212, 3934, 128, 995, 13724, 3934, 128, 15922, 3934, 128, 11474, 405, 3934, 128, 179, 35429, 3934, 128, 14377, 254, 3934, 128, 24648, 3934, 128, 45593, 3934, 128, 3245, 687, 3934, 128, 3530, 3934, 128, 11070, 3934, 128, 11173, 3934, 128, 175, 5489, 4060, 3934, 128, 9178, 3623, 3934, 128, 14596, 3934, 128, 27363, 1342, 783, 3934, 128, 3341, 3934, 128, 33234, 3934, 128, 31192, 3934, 128, 611, 1243, 3934, 128, 241, 12592, 3934, 128, 15476, 3934, 128, 20557, 3934, 128, 462, 2582, 462, 3934, 128, 15509, 3934, 128, 5877, 3934, 128, 21267, 1069, 3934, 128, 23233, 3934, 128, 37641, 3934, 128, 506, 1975, 257, 3934, 128, 36058, 3934, 128, 13728, 783, 3934, 128, 38908, 3934, 128, 10212, 3934, 128, 33008, 281, 3934, 128, 10111, 3934, 128, 179, 35429, 3934, 128, 24336, 3934, 128, 23286, 15892, 3934, 128, 29280, 710, 3934, 128, 1685, 118, 3934, 128, 1090, 3320, 20506, 3934, 128, 8490, 3934, 128, 462, 2582, 462, 3934, 128, 611, 1097, 3934, 128, 175, 5489, 3934, 128, 12361, 4193, 3934, 128, 4483, 3934, 128, 7904, 3109, 3934, 128, 26559, 3934, 128, 31938, 3934, 128, 10337, 3934, 128, 6298, 3934, 128, 46234, 3934, 128, 32639, 179, 3934, 128, 90, 10082, 3934, 128, 17830, 3934, 128, 11474, 405, 3934, 128, 3730, 3934, 128, 17212, 3934, 128, 46797, 3934, 128, 119, 5109, 118, 3934, 128, 32639, 179, 3934, 128, 29280, 710, 3934, 128, 10212, 3934, 128, 10111, 3934, 128, 31575, 3934, 128, 17193, 3934, 128, 2456, 17536, 3934, 128, 3314, 179, 3934, 128, 13139, 337, 3934, 128, 3006, 257, 3934, 128, 34020, 3934, 128, 90, 13157, 1116, 260, 3934, 128, 3314, 179, 3934, 128, 12516, 3934, 128, 27075, 16497, 1043, 3934, 128, 9232, 1290, 3934, 128, 11474, 405, 3934, 128, 19726, 3934, 128, 29668, 3934, 128, 1517, 31210, 3934, 128, 12516, 3934, 128, 24648, 3934, 128, 2456, 2614, 3934, 128, 23233, 3934, 128, 3341, 3934, 128, 38010, 3934, 128, 9424, 3934, 128, 1469, 11284, 3934, 128, 18658, 3934, 128, 241, 20401, 118, 3934, 128, 17193, 3934, 128, 21113, 3934, 128, 34001, 3934, 128, 17304, 3934, 128, 3707, 9041, 3934, 128, 4182, 4348, 3934, 128, 6622, 3934, 128, 20118, 3934, 128, 17212, 3934, 128, 1902, 3934, 128, 40499, 3934, 128, 8344, 6343, 3934, 128, 14189, 3934, 128, 17212, 3934, 128, 11474, 405, 3934, 128, 21267, 1069, 3934, 128, 119, 1488, 5101, 118, 3934, 128, 21267, 1069, 3934, 128, 37519, 462, 11032, 3934, 128, 21267, 1069, 3934, 128, 119, 1488, 5101, 118, 3934, 128, 23233, 3934, 128, 41908, 13850, 1512, 3934, 128, 3530, 3934, 128, 15509, 3934, 128, 17193, 3934, 128, 5777, 15696, 3934, 128, 38641, 118, 3934, 128, 21267, 1069, 3934, 128, 37519, 462, 11032, 3934, 128, 8355, 3934, 128, 15509, 3934, 128, 6930, 338, 1594, 3934, 128, 29, 26661, 3934, 128, 31499, 636, 3934, 128, 27887, 257, 3934, 128, 22930, 3934, 128, 241, 2987, 257, 3934, 128, 506, 1975, 257, 3934, 128, 18582, 3934, 128, 11828, 1543, 3934, 128, 17165, 24008, 368, 3934, 128, 2050, 3964, 3934, 128, 179, 9399, 6249, 3934, 128, 34664, 3934, 128, 1279, 3934, 128, 12488, 3934, 128, 3707, 9041, 3934, 128, 34001, 3934, 128, 24648, 3934, 128, 17304, 3934, 128, 32673, 3934, 128, 8355, 254, 3934, 128, 20122, 3934, 128, 700, 11132, 3934, 128, 6930, 338, 3934, 128, 8198, 1588, 3934, 128, 9426, 49012, 3934, 128, 16714, 3572, 3934, 128, 26149, 3934, 128, 32673, 3934, 128, 757, 13138, 3934, 128, 241, 2987, 257, 3934, 128, 9178, 3623, 3934, 128, 2544, 1290, 3934, 128, 11828, 594, 405, 3934, 128, 27390, 3934, 128, 34001, 3934, 128, 3275, 1949, 3934, 128, 1672, 3934, 128, 11474, 405, 3934, 128, 23411, 3934, 128, 20565, 3934, 128, 42843, 3934, 128, 119, 1488, 5101, 118, 3934, 128, 700, 11132, 3934, 128, 90, 20777, 3934, 128, 3463, 13771, 3934, 128, 23411, 3934, 128, 20565, 3934, 128, 241, 2987, 257, 3934, 128, 3707, 9041, 3934, 128, 29557, 3934, 128, 15509, 3934, 128, 4892, 11497, 118, 3934, 128, 33234, 3934, 128, 28310, 118, 3934, 128, 42843, 3934, 128, 119, 1488, 5101, 118, 3934, 128, 700, 11132, 3934, 128, 90, 20777, 3934, 128, 18658, 3934, 128, 9996, 8285, 3934, 128, 28310, 118, 3934, 128, 23286, 642, 3934, 128, 3707, 9041, 3934, 128, 42843, 3934, 128, 34276, 3934, 128, 90, 20777, 3934, 128, 15509, 3934, 128, 9671, 3934, 128, 17330, 3934, 128, 10839, 3934, 128, 1090, 1657, 3934, 128, 611, 879, 3934, 128, 19911, 44403], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode_plus(text, add_special_tokens=False)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokens['input_ids']\n",
    "attention_mask = tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1074"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48759, 119, 37205, 3934, 128, 18658, 3934, 128, 43140, 1397]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start = 0\n",
      "end = 512\n",
      "start = 512\n",
      "end = 1024\n",
      "start = 1024\n",
      "end = 1074\n"
     ]
    }
   ],
   "source": [
    "# Just a demonstration to visualize what the code should do:\n",
    "\n",
    "start = 0\n",
    "win_length = 512\n",
    "\n",
    "total_len = len(input_ids)\n",
    "\n",
    "loop = True\n",
    "\n",
    "while loop:\n",
    "    end = start + win_length\n",
    "    \n",
    "    if end >= total_len:\n",
    "        loop = False\n",
    "        end = total_len\n",
    "        \n",
    "    print(f'start = {start}')\n",
    "    print(f'end = {end}')\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_size(input_ids, attention_mask, total_len):\n",
    "    prob_list = []\n",
    "    start = 0\n",
    "    win_length = 510\n",
    "    loop = True\n",
    "\n",
    "    while loop:\n",
    "        end = start + win_length\n",
    "\n",
    "        if end >= total_len:\n",
    "            loop = False \n",
    "            end = total_len\n",
    "\n",
    "        # Defining the text chunk:\n",
    "        input_ids_chunk = input_ids[start:end]\n",
    "        attention_mask_chunk = attention_mask[start:end]\n",
    "\n",
    "        # Referring to specific classes:\n",
    "        input_ids_chunk = [101] + input_ids_chunk + [102]\n",
    "        attention_mask_chunk = [1] + attention_mask_chunk + [1]\n",
    "\n",
    "        # Convert to PyTorch Tensors:\n",
    "        input_dict = {'input_ids' : torch.Tensor([input_ids_chunk]).long(),\n",
    "                      'attention_mask' : torch.Tensor([attention_mask_chunk]).int()}\n",
    "        \n",
    "        outputs = model(**input_dict)\n",
    "        probabilities = torch.nn.functional.softmax(outputs[0], dim = -1)\n",
    "        prob_list.append(probabilities)\n",
    "\n",
    "        start = end\n",
    "\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[2.0609e-04, 9.9956e-01, 2.3495e-04]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[1.1697e-04, 9.9976e-01, 1.2434e-04]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[9.7182e-05, 9.9982e-01, 8.1408e-05]], grad_fn=<SoftmaxBackward0>)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_list = chunk_size(input_ids, attention_mask, total_len)\n",
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.0609e-04, 9.9956e-01, 2.3495e-04]],\n",
       "\n",
       "        [[1.1697e-04, 9.9976e-01, 1.2434e-04]],\n",
       "\n",
       "        [[9.7182e-05, 9.9982e-01, 8.1408e-05]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacks = torch.stack(prob_list)\n",
    "stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = stacks.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_from_prob(prob_list):\n",
    "    with torch.no_grad():\n",
    "        stacks = torch.stack(prob_list)\n",
    "\n",
    "        stacks = stacks.resize(stacks.shape[0], stacks.shape[2])\n",
    "\n",
    "        mean = stacks.mean(dim=0)\n",
    "\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:868: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.4008e-04, 9.9971e-01, 1.4690e-04])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = get_mean_from_prob(prob_list)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(mean).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
